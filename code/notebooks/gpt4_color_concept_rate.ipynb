{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline \n",
    "from IPython.display import clear_output\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "# import scipy\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "# import math\n",
    "# import gensim\n",
    "# from itertools import repeat\n",
    "# import gensim.downloader\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import statsmodels.api as sm\n",
    "# # from gensim.models.fasttext import load_facebook_mode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ratings_mat(grouped_ratings_df):\n",
    "    \n",
    "    mat = np.zeros((len(np.unique(grouped_ratings_df.prompt)),71))\n",
    "    for i,con in enumerate(np.unique(grouped_ratings_df.prompt)):\n",
    "        ds = grouped_ratings_df[grouped_ratings_df.prompt==con]\n",
    "        mat[i,:] = ds.iloc[:,3].values\n",
    "\n",
    "\n",
    "    mat = pd.DataFrame(mat, index =np.unique(grouped_ratings_df.prompt), columns = np.arange(mat.shape[1]) )\n",
    "    cmeans = mat.mean().values\n",
    "    return mat, cmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1_raw = pd.read_csv('../../data/uw71_set1_redo_raw.csv')\n",
    "set_2_raw = pd.read_csv('../../data/uw71_set2_raw.csv')\n",
    "set_3_raw = pd.read_csv('../../data/uw71_set3_raw.csv')\n",
    "set1_grouped = set_1_raw.groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "set2_grouped = set_2_raw.groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "set3_grouped = set_3_raw.groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "\n",
    "ratings1,ratings_cmeans1= make_ratings_mat(set1_grouped)\n",
    "ratings2,ratings_cmeans2= make_ratings_mat(set2_grouped)\n",
    "ratings3,ratings_cmeans3= make_ratings_mat(set3_grouped)\n",
    "\n",
    "concept_list = set1_grouped.pivot(index=['prompt','concept'], columns='color_index', values='mean_rating').reset_index().sort_values(by=['concept','prompt']).reset_index(drop=True)['prompt'].values\n",
    "concept_list.sort()\n",
    "concept_order  = {concept: i for i, concept in enumerate(concept_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw71coords = pd.read_csv('../../data/UW71coordinates_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vertically stack the ratings matrices\n",
    "ratings_all = pd.concat([ratings1,ratings2,ratings3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#2f6ef6, #3518ad, #8558f4, #b62ef2, #077acc, #2e3086, #746bca, #600b84, #a553c8, #cd26c7, #4dc7e8, #1c3d61, #5e78a1, #a0bae6, #512d5f, #90689f, #d5a9e4, #72005e, #b8509e, #db1f9d, #39f6e0, #3b8378, #7ec6ba, #a2eade, #000000, #3b3b3b, #777777, #b9b9b9, #ffffff, #dddddd, #5e2b3a, #a06776, #e6a8b7, #c34f74, #e31b73, #4bcf8e, #73f5b0, #184415, #55824d, #96c58c, #baeaaf, #443b14, #83764c, #c7b88b, #eddcad, #632b14, #a8664b, #f1a78a, #c94e4b, #e81a4b, #0e8a19, #67cf5c, #8cf47e, #608218, #a3c55b, #c8e97d, #897618, #d0b85a, #f7db7c, #ac6619, #f7a75a, #cc4f1b, #ea1d1d, #3efe44, #73cf10, #9af443, #aac510, #d0e942, #d5b811, #fcdb42, #fba714'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make a long string with all the entries in uw71coords.color_hex separated by commas\n",
    "all_color_string = ', '.join(uw71coords.color_hex.values)\n",
    "all_color_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('API_key_soil.txt') as f:\n",
    "    openai.api_key= f.readline()\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: beside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▌                                                                                            | 6/71 [00:06<01:04,  1.01it/s]"
     ]
    }
   ],
   "source": [
    "skip_concepts = ['above','angry','beach','below']\n",
    "reps=10\n",
    "\n",
    "assocs = np.zeros((70*reps,71))\n",
    "for i,this_concept in enumerate(ratings_all.index.values):\n",
    "  if this_concept in skip_concepts:\n",
    "    continue\n",
    "  for j in range(reps):\n",
    "\n",
    "    clear_output()\n",
    "    print(f'Evaluating: {this_concept}')\n",
    "\n",
    "    for k,this_color in enumerate(tqdm(uw71coords.color_hex.values)):\n",
    "\n",
    "      time.sleep(.333)\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\n",
    "              \"role\": \"system\",\n",
    "              \"content\": \"You are an expert on color-concept associations.\"\n",
    "            },\n",
    "\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": f\"I will give you the hexcode for a color and a concept word. Rate on a continuous scale from 0 to 1, using 3 decimal places, how associated the color is with the concept.\\\n",
    "              Let's do the rating task - \\\n",
    "      Concept: '{this_concept}'\\\n",
    "      Colors: {this_color}\\\n",
    "      Answer with only the number:\"\n",
    "            }],\n",
    "        temperature=1,\n",
    "        max_tokens=10\n",
    "      )\n",
    "      assocs[reps*i + j,k] = float(response.choices[0].message.content)\n",
    "    gpt_assoc_df = pd.DataFrame(assocs, index = np.repeat(ratings_all.index.values,reps), columns = np.arange(71))\n",
    "    gpt_assoc_df.to_csv('../../data/gpt4_ratings_multiple_2.csv')\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assocs = np.zeros((70,71))\n",
    "# for i,this_concept in enumerate(ratings_all.index.values):\n",
    "#   if this_concept in ([\n",
    "#     'above',\n",
    "# 'angry',\n",
    "# 'beach',\n",
    "# 'below',\n",
    "# 'beside',\n",
    "# 'blueberry',\n",
    "# 'dawn',\n",
    "# 'day',\n",
    "# 'disgust',\n",
    "# 'dress',\n",
    "# 'dusk',\n",
    "# 'far',\n",
    "# 'fearful',\n",
    "# 'field',\n",
    "# 'happy',\n",
    "# 'lemon',\n",
    "# 'mango',\n",
    "# 'near',\n",
    "# 'night',\n",
    "# 'noon',\n",
    "# 'ocean',\n",
    "# 'pants',\n",
    "# 'sad',\n",
    "# 'shirt',\n",
    "# 'shoes',\n",
    "# 'sky',\n",
    "# 'socks',\n",
    "# 'strawberry',\n",
    "# 'sunset',\n",
    "# 'watermelon',\n",
    "# 'bear',\n",
    "# 'bird',\n",
    "# 'blizzard',\n",
    "# 'boat',\n",
    "# 'car',\n",
    "# 'drought',\n",
    "# 'evil',\n",
    "# 'fish',\n",
    "# 'frog',\n",
    "# 'greed',\n",
    "# 'hurricane',\n",
    "# 'justice',\n",
    "# 'lightning',\n",
    "# 'lion',\n",
    "# 'love',\n",
    "# 'peace',\n",
    "# 'plane',\n",
    "# 'sandstorm']):\n",
    "#     continue\n",
    "#   clear_output()\n",
    "#   print(f'Evaluating:{this_concept}')\n",
    "\n",
    "#   for j,this_color in enumerate(tqdm(uw71coords.color_hex.values)):\n",
    "\n",
    "#     time.sleep(3)\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#       model=\"gpt-4\",\n",
    "#       messages=[{\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"You are an expert on color-concept associations.\"\n",
    "#           },\n",
    "\n",
    "#           {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": f\"I will give you the hexcode for a color a concept. Rate on a continuous scale from 0 to 1, using 3 decimal places, how associated the color is with the concept.\\\n",
    "#             The concept is '{this_concept}'.\\\n",
    "#             Before rating, here's the set of all the colors {all_color_string}. Think of which color you associate most with '{this_concept}', that color should get a rating of 1. Now think of\\\n",
    "#             which color you associated least with '{this_concept}', that color should get a rating of 0. Okay, now let's do the rating task.\\\n",
    "#     Concept: '{this_concept}'\\\n",
    "#     Color: {this_color}\\\n",
    "#     Answer with only the number:\"\n",
    "#           }],\n",
    "#       temperature=0,\n",
    "#       max_tokens=10\n",
    "#     )\n",
    "#     assocs[i,j] = float(response.choices[0].message.content)\n",
    "#   gpt_assoc_df = pd.DataFrame(assocs, index = ratings_all.index.values, columns = np.arange(71))\n",
    "#   gpt_assoc_df.to_csv('../../data/recon_assocs/gpt4_ratings_anchored_4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_assoc_anchor_df = pd.read_csv('../../data/gpt4_ratings_anchored_final.csv', index_col=0)\n",
    "gpt_assoc_noanchor_df = pd.read_csv('../../data/gpt4_ratings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assocs_justice = pd.read_csv('../../data/gpt4_ratings_justice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_cor_df[gpt_cor_df.concept=='justice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(71),assocs_justice.iloc[:3,1:].mean().values,color= uw71coords.color_hex.values)\n",
    "pearsonr(assocs_justice.iloc[0:3,1:].mean().values, ratings_all[ratings_all.index=='justice'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "### make the barplot of assocs and color each bar with the 71 colors in uw71coords.color_hex.values\n",
    "plt.bar(np.arange(71),gpt_assoc_anchor_df[gpt_assoc_anchor_df.index=='justice'].values[0], color = uw71coords.color_hex.values)\n",
    "plt.ylim([0,1])\n",
    "plt.title('GPT4 Color-Concept Associations Anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(71),gpt_assoc_noanchor_df[gpt_assoc_noanchor_df.index=='near'].values[0], color = uw71coords.color_hex.values)\n",
    "plt.ylim([0,1])\n",
    "plt.title('GPT4 Color-Concept Associations No Anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gpt_assoc_anchor_df[ratings_all.index=='happy'].values[0],gpt_assoc_noanchor_df[gpt_assoc_noanchor_df.index=='happy'].values[0], color = uw71coords.color_hex.values)\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel('Human')\n",
    "plt.ylabel('No Anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(71),ratings_all[ratings_all.index=='justice'].values[0], color = uw71coords.color_hex.values)\n",
    "plt.ylim([0,1])\n",
    "plt.title('Human Color-Concept Associations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(gpt_assoc_df[gpt_assoc_df.index=='greed'].values[0],ratings_all[ratings_all.index=='greed'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons =[]\n",
    "cors_noanchor = []\n",
    "cors_anchor = []\n",
    "spec=[]\n",
    "for this_concept in gpt_assoc_df.index:\n",
    "    cons.append(this_concept)\n",
    "    cors_noanchor.append(pearsonr(gpt_assoc_noanchor_df[gpt_assoc_noanchor_df.index==this_concept].values[0],ratings_all[ratings_all.index==this_concept].values[0])[0])\n",
    "    cors_anchor.append(pearsonr(gpt_assoc_anchor_df[gpt_assoc_anchor_df.index==this_concept].values[0],ratings_all[ratings_all.index==this_concept].values[0])[0])\n",
    "    \n",
    "    spec.append(1/entropy(ratings_all[ratings_all.index==this_concept].values[0]))\n",
    "gpt_cor_df = pd.DataFrame({'concept':cons,'cor_noanchor':cors_noanchor,'cor_anchor': cors_anchor,'specificity':spec})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort gpt_cor_df by the correlation values and plot them as a barplot\n",
    "plt.figure(figsize=(10,5))\n",
    "gpt_cor_df.sort_values(by='cor_noanchor', inplace=True)\n",
    "plt.bar(np.arange(70),gpt_cor_df.cor_noanchor.values, color='grey')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(70),gpt_cor_df.concept.values, rotation=90)\n",
    "plt.title('GPT4 Color-Concept Correlations No Anchor')\n",
    "print('mean correlation:',gpt_cor_df.cor_noanchor.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort gpt_cor_df by the correlation values and plot them as a barplot\n",
    "plt.figure(figsize=(10,5))\n",
    "gpt_cor_df.sort_values(by='cor_anchor', inplace=True)\n",
    "plt.bar(np.arange(70),gpt_cor_df.cor_anchor.values, color='grey')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(70),gpt_cor_df.concept.values, rotation=90)\n",
    "plt.title('GPT4 Color-Concept Correlations Anchor')\n",
    "print('mean correlation:',gpt_cor_df.cor_anchor.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_cor_df\n",
    "\n",
    "## plot gpt_cor_df.cor_noanchor and gpt_cor_df.cor_anchor as overlapping barplots. make the bars transparent\n",
    "gpt_cor_df = gpt_cor_df.sort_values(by='cor_noanchor', ascending=True)\n",
    "plt.figure(figsize=(10,5))\n",
    "# gpt_cor_df.sort_values(by='cor_anchor', inplace=True)\n",
    "plt.bar(np.arange(70),gpt_cor_df.cor_anchor.values, color='#dec104', alpha=1)\n",
    "plt.bar(np.arange(70),gpt_cor_df.cor_noanchor.values, color='blue', alpha=.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(70),gpt_cor_df.concept.values, rotation=90)\n",
    "plt.title('GPT4 Color-Concept Correlations Anchor & No Anchor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split half cors\n",
    "\n",
    "\n",
    "g1_subs = np.random.choice(set_1_raw[set_1_raw.prompt=='happy'].subject_id, 25, replace=False)\n",
    "g2_subs = np.setdiff1d(set_1_raw[set_1_raw.prompt=='happy'].subject_id, g1_subs)\n",
    "g1_grouped = set_1_raw[set_1_raw.subject_id.isin(g1_subs)].groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "g2_grouped = set_1_raw[set_1_raw.subject_id.isin(g2_subs)].groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "g1_ratings = make_ratings_mat(g1_grouped)[0]\n",
    "g2_ratings = make_ratings_mat(g2_grouped)[0]\n",
    "\n",
    "g1_happy = g1_ratings[g1_ratings.index=='happy']\n",
    "g2_happy = g2_ratings[g2_ratings.index=='happy']\n",
    "\n",
    "## compute the correlation between g1_happy and g2_happy with the spearman brown correction\n",
    "corrected_sh = 2*pearsonr(g1_happy.values[0],g2_happy.values[0])[0]/(1+pearsonr(g1_happy.values[0],g2_happy.values[0])[0])\n",
    "corrected_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw = pd.concat([set_1_raw,set_2_raw,set_3_raw])\n",
    "corrected_shs = []\n",
    "con=[]\n",
    "for i in range(30):\n",
    "    for this_concept in ratings_all.index:\n",
    "        this_concept_ratings = all_raw[all_raw.prompt==this_concept]\n",
    "        sub_1 = np.random.choice(this_concept_ratings.subject_id.unique(), int(this_concept_ratings.subject_id.nunique()/2), replace=False)\n",
    "        sub_2 = np.setdiff1d(this_concept_ratings.subject_id, sub_1)\n",
    "        g1_grouped = this_concept_ratings[this_concept_ratings.subject_id.isin(sub_1)].groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "        g2_grouped = this_concept_ratings[this_concept_ratings.subject_id.isin(sub_2)].groupby(['concept','prompt','color_index']).response.agg(mean_rating = 'mean', se ='sem').reset_index()\n",
    "        g1_ratings = make_ratings_mat(g1_grouped)[0]\n",
    "        g2_ratings = make_ratings_mat(g2_grouped)[0]\n",
    "        con.append(this_concept)\n",
    "        corrected_shs.append(2*pearsonr(g1_ratings.values[0],g2_ratings.values[0])[0]/(1+pearsonr(g1_ratings.values[0],g2_ratings.values[0])[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_df = pd.DataFrame({'concept':con,'sh':corrected_shs})\n",
    "mean_sh_df = sh_df.groupby('concept').sh.agg(mean_sh='mean').reset_index()\n",
    "mean_sh_df=mean_sh_df.sort_values(by='mean_sh', ascending=True)\n",
    "concept_order = {concept: i for i, concept in enumerate(mean_sh_df.sort_values(by='mean_sh', ascending=True).concept.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,5))\n",
    "### sort sh_df by concept and do it in the order of the concept_order dictionary\n",
    "sh_df['order'] = sh_df.concept.map(concept_order)\n",
    "sh_df.sort_values(by='order', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x='concept', y='sh',data=sh_df, color='grey')\n",
    "plt.ylim(0,1)\n",
    "### rotate the xticks by 90 degrees\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Human Color-Concept Split Half Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(mean_sh_df.concept.values, gpt_cor_df.concept.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(mean_sh_df.sort_values(by='concept').mean_sh.values, gpt_cor_df.sort_values(by='concept').cor.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_cor_df.sort_values(by='concept',inplace=True)\n",
    "mean_sh_df.sort_values(by='concept',inplace=True)\n",
    "gpt_cor_df['cor'] = gpt_cor_df.cor/mean_sh_df.mean_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "gpt_cor_df.sort_values(by='cor', inplace=True)\n",
    "plt.bar(np.arange(70),gpt_cor_df.cor.values, color='grey')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(np.arange(70),gpt_cor_df.concept.values, rotation=90)\n",
    "plt.title('GPT4 Color-Concept Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
